using Amazon.BedrockRuntime;
using Amazon.BedrockRuntime.Model;
using Microsoft.Extensions.Caching.Memory;
using System.Security.Cryptography;
using System.Text;
using System.Text.Json;
using TextractProcessor.Models;

namespace TextractProcessor.Services
{
    /// <summary>
    /// Service for processing Textract results through Amazon Bedrock's language models
    /// </summary>
    public class BedrockService
    {
        private readonly IAmazonBedrockRuntime _bedrockClient;
        private readonly IMemoryCache _cache;

        private const string MODEL_ID = "anthropic.claude-v2";
        private const int CACHE_DURATION_MINUTES = 60;
        private const int MAX_TOKENS = 8000;
        private const float TEMPERATURE = 0.5f;
        private const float TOP_P = 0.9f;

        public BedrockService(IAmazonBedrockRuntime bedrockClient, IMemoryCache cache)
        {
            _bedrockClient = bedrockClient ?? throw new ArgumentNullException(nameof(bedrockClient));
            _cache = cache ?? throw new ArgumentNullException(nameof(cache));
        }

        /// <summary>
        /// Processes Textract results and maps them to the target schema using Bedrock's AI model
        /// </summary>
        /// <param name="textractResults">The results from Textract processing</param>
        /// <param name="targetSchema">The target schema to map the results to</param>
        /// <returns>Tuple containing the response, input token count, and output token count</returns>
        public async Task<(string response, int inputTokens, int outputTokens)> ProcessTextractResults(
            TextractResponse textractResults,
            string targetSchema)
        {
            if (textractResults == null) throw new ArgumentNullException(nameof(textractResults));
            if (string.IsNullOrWhiteSpace(targetSchema)) throw new ArgumentException("Target schema cannot be empty", nameof(targetSchema));

            // Create and hash the prompt for caching
            var prompt = CreatePrompt(textractResults, targetSchema);
            var promptHash = CalculateHash(prompt);

            // Try to get from cache
            if (_cache.TryGetValue<CachedResponse>(promptHash, out var cachedResponse))
            {
                return (cachedResponse.Response, cachedResponse.InputTokens, cachedResponse.OutputTokens);
            }

            // Process with Bedrock
            var response = await InvokeBedrockModel(prompt);
            
            // Calculate token usage
            var inputTokens = EstimateTokenCount(prompt);
            var outputTokens = EstimateTokenCount(response.Completion);

            // Cache the results
            var cacheEntry = new CachedResponse
            {
                Response = response.Completion,
                InputTokens = inputTokens,
                OutputTokens = outputTokens
            };

            _cache.Set(promptHash, cacheEntry, TimeSpan.FromMinutes(CACHE_DURATION_MINUTES));

            return (response.Completion, inputTokens, outputTokens);
        }

        /// <summary>
        /// Invokes the Bedrock model with the given prompt
        /// </summary>
        private async Task<BedrockResponse> InvokeBedrockModel(string prompt)
        {
            var request = new InvokeModelRequest
            {
                ModelId = MODEL_ID,
                ContentType = "application/json",
                Accept = "application/json",
                Body = new MemoryStream(Encoding.UTF8.GetBytes(JsonSerializer.Serialize(new
                {
                    prompt = $"Human: {prompt}\n\nAssistant: I'll help you transform the Textract results into the target schema format.",
                    max_tokens_to_sample = MAX_TOKENS,
                    temperature = TEMPERATURE,
                    top_p = TOP_P
                })))
            };

            var response = await _bedrockClient.InvokeModelAsync(request);
            using var reader = new StreamReader(response.Body);
            var responseJson = await reader.ReadToEndAsync();
     
            return JsonSerializer.Deserialize<BedrockResponse>(responseJson) 
       ?? throw new InvalidOperationException("Failed to deserialize Bedrock response");
        }

        /// <summary>
        /// Creates a hash of the input string for caching purposes
        /// </summary>
        private static string CalculateHash(string input)
        {
            using var sha256 = SHA256.Create();
            var bytes = Encoding.UTF8.GetBytes(input);
            var hash = sha256.ComputeHash(bytes);
            return Convert.ToBase64String(hash);
        }

        /// <summary>
        /// Creates the prompt for the AI model
        /// </summary>
        private static string CreatePrompt(TextractResponse textractResults, string targetSchema)
        {
            return $@"
Transform the following Textract extracted data into the specified target schema.

Textract Results:
{JsonSerializer.Serialize(textractResults, new JsonSerializerOptions { WriteIndented = true })}

Target Schema:
{targetSchema}

Generate a JSON object that follows the target schema structure, filling in the appropriate values from the Textract results.
Only include fields where you have high confidence in the mapping.
For numeric values, ensure they are properly formatted.
For dates, use the format specified in the schema.";
        }

        /// <summary>
        /// Estimates the token count for a given text
        /// </summary>
        private static int EstimateTokenCount(string text)
        {
            // Rough estimation: GPT tokens are roughly 4 characters
            return (int)(text.Length / 4);
        }
    }

    /// <summary>
    /// Represents a response from the Bedrock model
    /// </summary>
    public class BedrockResponse
    {
        public string Completion { get; set; } = string.Empty;
        public string StopReason { get; set; } = string.Empty;
        public int TokensUsed { get; set; }
    }

    /// <summary>
    /// Represents a cached response from the model
    /// </summary>
    public class CachedResponse
    {
        public string Response { get; set; } = string.Empty;
        public int InputTokens { get; set; }
        public int OutputTokens { get; set; }
        public DateTime CachedAt { get; set; } = DateTime.UtcNow;
    }
}