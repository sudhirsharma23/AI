using Amazon;
using Amazon.BedrockRuntime;
using Amazon.BedrockRuntime.Model;
using Amazon.Lambda.Core;
using Microsoft.Extensions.Caching.Memory;
using System.Security.Cryptography;
using System.Text;
using System.Text.Json;
using System.Text.Json.Serialization;
using TextractProcessor.Models;

namespace TextractProcessor.Services
{
    public class SnakeCaseNamingPolicy : JsonNamingPolicy
    {
        public override string ConvertName(string name)
        {
            if (string.IsNullOrEmpty(name)) return name;

            var builder = new StringBuilder();
            for (var i = 0; i < name.Length; i++)
            {
                if (i > 0 && char.IsUpper(name[i]))
                {
                    builder.Append('_');
                }
                builder.Append(char.ToLower(name[i]));
            }
            return builder.ToString();
        }
    }

    public class BedrockService
    {
        private readonly IAmazonBedrockRuntime _bedrockClient;
        private readonly IMemoryCache _cache;
        private readonly BedrockModelConfig _modelConfig;
        private const int CACHE_DURATION_MINUTES = 60;
        private static readonly JsonSerializerOptions _jsonOptions = new()
        {
            PropertyNamingPolicy = new SnakeCaseNamingPolicy(),
            DefaultIgnoreCondition = JsonIgnoreCondition.WhenWritingNull
        };

        public BedrockService(IAmazonBedrockRuntime bedrockClient,IMemoryCache cache,BedrockModelConfig modelConfig = null)
        {
            _bedrockClient = bedrockClient ?? throw new ArgumentNullException(nameof(bedrockClient));
            _cache = cache ?? throw new ArgumentNullException(nameof(cache));
            _modelConfig = modelConfig ?? BedrockModelConfig.NovaLite;
        }

        public async Task<(string response, int inputTokens, int outputTokens)> ProcessTextractResults(SimplifiedTextractResponse textractResults, string targetSchema, ILambdaContext context = null)
        {

            try
            {
                // Call temp model to keep the model warm
                //await CallTempModel();  // Added await here


                if (textractResults == null) throw new ArgumentNullException(nameof(textractResults));
                if (string.IsNullOrWhiteSpace(targetSchema)) throw new ArgumentException("Target schema cannot be empty", nameof(targetSchema));

                var requestId = context?.AwsRequestId ?? Guid.NewGuid().ToString();
                context?.Logger.LogLine($"[RequestId: {requestId}] Starting Textract processing");

                // Calculate hash for caching
                var cacheKey = CalculateHash(JsonSerializer.Serialize(textractResults) + targetSchema + _modelConfig.ModelId);

                if (_cache.TryGetValue<CachedResponse>(cacheKey, out var cachedResponse))
                {
                    context?.Logger.LogLine($"[RequestId: {requestId}] Cache hit - returning cached response");
                    return (cachedResponse.Response, cachedResponse.InputTokens, cachedResponse.OutputTokens);
                }

                context?.Logger.LogLine($"[RequestId: {requestId}] Cache miss - processing with Bedrock");
                var prompt = CreatePrompt(textractResults, targetSchema);
                context?.Logger.LogLine($"[RequestId: {requestId}] Invoking Bedrock model {_modelConfig.ModelId}");

                // Create model-specific request
                var request = CreateModelRequest(prompt);
                var requestJson = JsonSerializer.Serialize(request, _jsonOptions);
                context?.Logger.LogLine($"[RequestId: {requestId}] Request JSON: {requestJson}");

                var modelRequest = new InvokeModelRequest
                {
                    ModelId = _modelConfig.ModelId,
                    ContentType = "application/json",
                    Accept = "application/json",
                    Body = new MemoryStream(Encoding.UTF8.GetBytes(requestJson))
                };

                context?.Logger.LogLine($"[RequestId: {requestId}] Sending request to Bedrock");
                var startTime = DateTime.UtcNow;
                var response = await _bedrockClient.InvokeModelAsync(modelRequest);
                var duration = DateTime.UtcNow - startTime;
                context?.Logger.LogLine($"[RequestId: {requestId}] Bedrock response received in {duration.TotalMilliseconds:F0}ms");

                using var reader = new StreamReader(response.Body);
                var responseJson = await reader.ReadToEndAsync();

                var (outputText, inputTokens, outputTokens) = ParseResponse(responseJson);
                context?.Logger.LogLine($"[RequestId: {requestId}] Processing metrics:" +
                       $"\n- Input tokens: {inputTokens}" +
                        $"\n- Output tokens: {outputTokens}" +
                         $"\n- Response size: {outputText.Length} chars");

                var cacheEntry = new CachedResponse
                {
                    Response = outputText,
                    InputTokens = inputTokens,
                    OutputTokens = outputTokens
                };

                _cache.Set(cacheKey, cacheEntry, TimeSpan.FromMinutes(CACHE_DURATION_MINUTES));
                context?.Logger.LogLine($"[RequestId: {requestId}] Response cached with key: {cacheKey}");

                return (outputText, inputTokens, outputTokens);
            }
            catch (Exception e)
            {
                context?.Logger.LogLine($"Error in Bedrock service: {e.Message}\nStack trace: {e.StackTrace}");
                throw;
            }
        }

        private object CreateModelRequest(string prompt)
        {
            // Always use Titan format since Nova Lite requires inference profile
            return new
            {
                inputText = prompt,
                textGenerationConfig = new
                {
                 maxTokenCount = _modelConfig.MaxTokens,
             temperature = _modelConfig.Temperature,
             topP = _modelConfig.TopP,
            stopSequences = Array.Empty<string>()
                }
            };
        }

        private (string outputText, int inputTokens, int outputTokens) ParseResponse(string responseJson)
        {
            var options = new JsonSerializerOptions
            {
      PropertyNameCaseInsensitive = true
    };

            // Always parse as Titan response
            return ParseTitanResponse(responseJson, options);
        }

        private static (string, int, int) ParseTitanResponse(string responseJson, JsonSerializerOptions options)
        {
            var response = JsonSerializer.Deserialize<TitanResponse>(responseJson, options);
            if (response?.Results == null || response.Results.Count == 0)
            {
                throw new InvalidOperationException($"Invalid Titan response format: {responseJson}");
            }

            return (
        response.Results[0].OutputText,
      response.Results[0].InputTextTokenCount,
            response.Results[0].OutputTextTokenCount
          );
        }

        private static (string, int, int) ParseClaudeResponse(string responseJson, JsonSerializerOptions options)
        {
            var response = JsonSerializer.Deserialize<ClaudeResponse>(responseJson, options);
            return (
 response?.Content ?? string.Empty,
     response?.Usage?.InputTokens ?? EstimateTokenCount(responseJson),
      response?.Usage?.OutputTokens ?? EstimateTokenCount(response?.Content)
            );
        }

        private static string CreatePrompt(SimplifiedTextractResponse textractResults, string targetSchema)
        {
            // Ensure we have data to process
            if (string.IsNullOrEmpty(textractResults.RawText) &&
  (textractResults.FormFields == null || !textractResults.FormFields.Any()) &&
    (textractResults.TableData == null || !textractResults.TableData.Any()))
            {
                throw new ArgumentException("No data available in the textract results to process");
            }

            // Serialize the source data
            var sourceData = JsonSerializer.Serialize(textractResults, new JsonSerializerOptions
            {
                WriteIndented = true,
                DefaultIgnoreCondition = JsonIgnoreCondition.WhenWritingNull
            });

            return $@"Transform the following source data into a JSON object that matches the target schema structure.

Source Data:
{sourceData}

Target Schema:
{targetSchema}

Rules:
- Create a valid JSON object
- Use proper data types (numbers without quotes, strings with quotes)
- Use YYYY-MM-DD for dates
- Use null for unmapped required fields
- Match property names exactly
- Return only the JSON object

Output Format: Return a valid JSON object only, no additional text or explanations.";
        }

        private static string CalculateHash(string input)
        {
            using var sha256 = SHA256.Create();
            var bytes = Encoding.UTF8.GetBytes(input);
            var hash = sha256.ComputeHash(bytes);
            return Convert.ToBase64String(hash);
        }

        private static int EstimateTokenCount(string text)
        {
            return text?.Length / 4 ?? 0;
        }
    }

    public class ClaudeResponse
    {
        public string Content { get; set; } = string.Empty;
        public Usage Usage { get; set; }
    }

    public class Usage
    {
        public int InputTokens { get; set; }
        public int OutputTokens { get; set; }
    }

    public class TitanResponse
    {
        public List<TitanResult> Results { get; set; } = new();
    }

    public class TitanResult
    {
        public string OutputText { get; set; } = string.Empty;
        public string CompletionReason { get; set; } = string.Empty;
        public int InputTextTokenCount { get; set; }
        public int OutputTextTokenCount { get; set; }
    }

    public class CachedResponse
    {
        public string Response { get; set; } = string.Empty;
        public int InputTokens { get; set; }
        public int OutputTokens { get; set; }
        public DateTime CachedAt { get; set; } = DateTime.UtcNow;
    }

    //      private async Task CallTempModel()
    //      {
    //          try
    //          {
    //              var client = new AmazonBedrockRuntimeClient(RegionEndpoint.USEast1); // Changed to us-east-1 where Nova is available
    //              var modelId = "amazon.nova-lite-v1:0"; // Changed from aws:amazon to amazon

    //              var request = new
    //              {
    //                  messages = new[]
    //{
    //  new
    //   {
    //            role = "user",
    //    content = new[]
    //           {
    //new { text = "Describe the purpose of a 'hello world' program in one line." }
    //        }
    //       }
    //  }
    //              };

    //              var requestJson = JsonSerializer.Serialize(request, _jsonOptions);
    //              Console.WriteLine($"Request JSON: {requestJson}"); // Added for debugging

    //              var modelRequest = new InvokeModelRequest
    //              {
    //                  ModelId = modelId,
    //                  ContentType = "application/json",
    //                  Accept = "application/json",
    //                  Body = new MemoryStream(Encoding.UTF8.GetBytes(requestJson))
    //              };

    //              // Send the request to Bedrock
    //              var response = await client.InvokeModelAsync(modelRequest);

    //              using var reader = new StreamReader(response.Body);
    //              var responseJson = await reader.ReadToEndAsync();
    //              Console.WriteLine($"Response: {responseJson}");
    //          }
    //          catch (AmazonBedrockRuntimeException e)
    //          {
    //              Console.WriteLine($"ERROR: Can't invoke Nova Lite model. Reason: {e.Message}");
    //              throw;
    //          }
    //      }

}